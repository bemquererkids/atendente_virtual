# âœ… agente_memoria.py â€” agente com memÃ³ria e entrada via "input" padrÃ£o
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain.agents import Tool, initialize_agent
from app.memoria.historico_redis import obter_historico_usuario
from app.tools.especialidade_tool import responder_especialidade

# ğŸ”§ LLM configurado com temperatura baixa para consistÃªncia
llm = ChatOpenAI(model="gpt-4", temperature=0.3)

# ğŸ“¦ Tool Ãºnica â€” responder especialidade com JSON ou texto livre
ferramentas = [
    Tool(
        name="responder_especialidade",
        func=responder_especialidade,
        description=(
            "Use esta ferramenta para responder perguntas sobre especialidades da clÃ­nica.\n"
            "Aceita: {'clinica_id': 'bemquerer', 'especialidade': 'implante'} ou texto com [clinica_id: bemquerer]"
        )
    )
]

# ğŸ“œ Prompt com histÃ³rico de conversa e chave 'input'
prompt = ChatPromptTemplate.from_messages([
    ("system", "VocÃª Ã© uma secretÃ¡ria atenciosa e acolhedora de uma clÃ­nica odontolÃ³gica."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

# ğŸ§  Agente com memÃ³ria (Redis) e entrada padronizada
agente_com_memoria = RunnableWithMessageHistory(
    initialize_agent(
        tools=ferramentas,
        llm=llm,
        agent_type="chat-zero-shot-react-description",
        verbose=True,
        handle_parsing_errors=True
    ),
    lambda session_id: obter_historico_usuario(session_id),
    input_messages_key="input",
    history_messages_key="history"
)